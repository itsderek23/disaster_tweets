{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Intro \n",
    "\n",
    "In this competition, you’re challenged to build a machine learning model that predicts which Tweets are about real disasters and which one’s aren’t.\n",
    "\n",
    "![](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcTigQWzoYCNiDyrz1BN4WTf2X2k9OZ_yvW-FsmcIMsdS9fppNmh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's in this kernel?\n",
    "- Basic EDA\n",
    "- Data Cleaning\n",
    "- Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required Libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# OPTIONAL: always reload modules so that as you change code in src, it gets loaded\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import disaster_tweets\n",
    "from disaster_tweets.util.notebook_imports import *\n",
    "from disaster_tweets.util.dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data and getting basic idea "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet, test = dataset_to_df()\n",
    "tweet.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('There are {} rows and {} columns in train'.format(tweet.shape[0],tweet.shape[1]))\n",
    "print('There are {} rows and {} columns in train'.format(test.shape[0],test.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we begin with anything else,let's check the class distribution.There are only two classes 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tweet.target.value_counts()\n",
    "sns.barplot(x.index,x)\n",
    "plt.gca().set_ylabel('samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ohh,as expected ! There is a class distribution.There are more tweets with class 0 ( No disaster) than class 1 ( disaster tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis of tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First,we will do very basic analysis,that is character level,word level and sentence level analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of characters in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "tweet_len=tweet[tweet['target']==1]['text'].str.len()\n",
    "ax1.hist(tweet_len,color='red')\n",
    "ax1.set_title('disaster tweets')\n",
    "tweet_len=tweet[tweet['target']==0]['text'].str.len()\n",
    "ax2.hist(tweet_len,color='green')\n",
    "ax2.set_title('Not disaster tweets')\n",
    "fig.suptitle('Characters in tweets')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of both seems to be almost same.120 t0 140 characters in a tweet are the most common among both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of words in a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "tweet_len=tweet[tweet['target']==1]['text'].str.split().map(lambda x: len(x))\n",
    "ax1.hist(tweet_len,color='red')\n",
    "ax1.set_title('disaster tweets')\n",
    "tweet_len=tweet[tweet['target']==0]['text'].str.split().map(lambda x: len(x))\n",
    "ax2.hist(tweet_len,color='green')\n",
    "ax2.set_title('Not disaster tweets')\n",
    "fig.suptitle('Words in a tweet')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Average word length in a tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,5))\n",
    "word=tweet[tweet['target']==1]['text'].str.split().apply(lambda x : [len(i) for i in x])\n",
    "sns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='red')\n",
    "ax1.set_title('disaster')\n",
    "word=tweet[tweet['target']==0]['text'].str.split().apply(lambda x : [len(i) for i in x])\n",
    "sns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='green')\n",
    "ax2.set_title('Not disaster')\n",
    "fig.suptitle('Average word length in each tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_corpus(target):\n",
    "    corpus=[]\n",
    "    \n",
    "    for x in tweet[tweet['target']==target]['text'].str.split():\n",
    "        for i in x:\n",
    "            corpus.append(i)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common stopwords in tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we  will analyze tweets with class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=create_corpus(0)\n",
    "\n",
    "dic=defaultdict(int)\n",
    "for word in corpus:\n",
    "    if word in stop:\n",
    "        dic[word]+=1\n",
    "        \n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=zip(*top)\n",
    "plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,we will analyze tweets with class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=create_corpus(1)\n",
    "\n",
    "dic=defaultdict(int)\n",
    "for word in corpus:\n",
    "    if word in stop:\n",
    "        dic[word]+=1\n",
    "\n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "    \n",
    "\n",
    "\n",
    "x,y=zip(*top)\n",
    "plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In both of them,\"the\" dominates which is followed by \"a\" in class 0 and \"in\" in class 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing punctuations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's check tweets indicating real disaster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "corpus=create_corpus(1)\n",
    "\n",
    "dic=defaultdict(int)\n",
    "import string\n",
    "special = string.punctuation\n",
    "for i in (corpus):\n",
    "    if i in special:\n",
    "        dic[i]+=1\n",
    "        \n",
    "x,y=zip(*dic.items())\n",
    "plt.bar(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,we will move on to class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "corpus=create_corpus(0)\n",
    "\n",
    "dic=defaultdict(int)\n",
    "import string\n",
    "special = string.punctuation\n",
    "for i in (corpus):\n",
    "    if i in special:\n",
    "        dic[i]+=1\n",
    "        \n",
    "x,y=zip(*dic.items())\n",
    "plt.bar(x,y,color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common words ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counter=Counter(corpus)\n",
    "most=counter.most_common()\n",
    "x=[]\n",
    "y=[]\n",
    "for word,count in most[:40]:\n",
    "    if (word not in stop) :\n",
    "        x.append(word)\n",
    "        y.append(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(x=y,y=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lot of cleaning needed !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ngram analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will do a bigram (n=2) analysis over the tweets.Let's check the most common bigrams in tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_tweet_bigrams(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(2, 2)).fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "top_tweet_bigrams=get_top_tweet_bigrams(tweet['text'])[:10]\n",
    "x,y=map(list,zip(*top_tweet_bigrams))\n",
    "sns.barplot(x=y,y=x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "disaster_tweets",
   "language": "python",
   "name": "disaster_tweets"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
